{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MusicGen </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Install Dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.5.0.post0)\n",
      "Requirement already satisfied: audiocraft in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.4.0a2)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: torchaudio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: librosa in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: matplotlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.2.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (0.12.0)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (24.2)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (1.3.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (4.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lightning) (2.5.0.post0)\n",
      "Requirement already satisfied: av==11.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (11.0.0)\n",
      "Requirement already satisfied: einops in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.8.1)\n",
      "Requirement already satisfied: flashy>=0.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.0.2)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (1.3.2)\n",
      "Requirement already satisfied: hydra_colorlog in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (1.2.0)\n",
      "Requirement already satisfied: julius in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.2.7)\n",
      "Requirement already satisfied: num2words in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.5.14)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.2.0)\n",
      "Requirement already satisfied: spacy==3.7.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (3.7.6)\n",
      "Collecting torch\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.33.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (4.41.2)\n",
      "Requirement already satisfied: xformers<0.0.23 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.0.22.post7)\n",
      "Requirement already satisfied: demucs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (4.0.1)\n",
      "Requirement already satisfied: soundfile in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.13.1)\n",
      "Requirement already satisfied: gradio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (5.18.0)\n",
      "Requirement already satisfied: encodec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.1.1)\n",
      "Requirement already satisfied: protobuf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (4.23.4)\n",
      "Requirement already satisfied: torchvision==0.16.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.16.0)\n",
      "Requirement already satisfied: torchtext==0.16.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.16.0)\n",
      "Requirement already satisfied: pesq in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.0.4)\n",
      "Requirement already satisfied: pystoi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.4.1)\n",
      "Requirement already satisfied: torchdiffeq in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from audiocraft) (0.2.5)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (0.15.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (2.10.6)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (75.8.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from spacy==3.7.6->audiocraft) (3.5.0)\n",
      "Requirement already satisfied: torchdata==0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchtext==0.16.0->audiocraft) (0.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.16.0->audiocraft) (11.1.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchdata==0.7.0->torchtext==0.16.0->audiocraft) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: dora_search in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flashy>=0.0.1->audiocraft) (0.1.12)\n",
      "Requirement already satisfied: colorlog in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flashy>=0.0.1->audiocraft) (6.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.12)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hydra-core>=1.1->audiocraft) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from hydra-core>=1.1->audiocraft) (4.9.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from soundfile->audiocraft) (1.17.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.31.0->audiocraft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.31.0->audiocraft) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.31.0->audiocraft) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub->audiocraft) (1.1.3)\n",
      "Requirement already satisfied: lameenc>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from demucs->audiocraft) (1.8.1)\n",
      "Requirement already satisfied: openunmix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from demucs->audiocraft) (1.3.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (1.7.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.28.1)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (3.10.15)\n",
      "Requirement already satisfied: pydub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.9.7)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.13.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio->audiocraft) (0.34.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio->audiocraft) (14.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from num2words->audiocraft) (0.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->audiocraft) (1.3.1)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.0->soundfile->audiocraft) (2.22)\n",
      "Requirement already satisfied: certifi in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->audiocraft) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->audiocraft) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->audiocraft) (0.14.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.6->audiocraft) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6->audiocraft) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6->audiocraft) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.6->audiocraft) (3.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.6->audiocraft) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.6->audiocraft) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.7.6->audiocraft) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.7.6->audiocraft) (7.1.0)\n",
      "Requirement already satisfied: retrying in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from dora_search->flashy>=0.0.1->audiocraft) (1.3.4)\n",
      "Requirement already satisfied: submitit in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from dora_search->flashy>=0.0.1->audiocraft) (1.5.2)\n",
      "Requirement already satisfied: treetable in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from dora_search->flashy>=0.0.1->audiocraft) (0.2.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.6->audiocraft) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy==3.7.6->audiocraft) (1.17.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from submitit->dora_search->flashy>=0.0.1->audiocraft) (3.1.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6->audiocraft) (0.1.2)\n",
      "Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m164.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m214.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m207.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m202.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m212.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m204.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.3.1\n",
      "    Uninstalling triton-3.3.1:\n",
      "      Successfully uninstalled triton-3.3.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.26.2\n",
      "    Uninstalling nvidia-nccl-cu12-2.26.2:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
      "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.1\n",
      "    Uninstalling torch-2.7.1:\n",
      "      Successfully uninstalled torch-2.7.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.7.1\n",
      "    Uninstalling torchaudio-2.7.1:\n",
      "      Successfully uninstalled torchaudio-2.7.1\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchaudio-2.1.0 triton-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:41 and /etc/apt/sources.list:44\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:41 and /etc/apt/sources.list:44\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (restricted/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:41 and /etc/apt/sources.list:44\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (restricted/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:41 and /etc/apt/sources.list:44\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (universe/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:48 and /etc/apt/sources.list:51\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (universe/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:48 and /etc/apt/sources.list:51\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (multiverse/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list:55 and /etc/apt/sources.list:58\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mTarget Packages (multiverse/binary-all/Packages) is configured multiple times in /etc/apt/sources.list:55 and /etc/apt/sources.list:58\u001b[0m\n",
      "fatal: destination path 'audiocraft' already exists and is not an empty directory.\n",
      "\n",
      "\n",
      "\u001b[38;5;57m\u001b[1m⚡️ Tip\u001b[0m\tConnect GitHub to Studios: \u001b[4mhttps://lightning.ai/omarash-dev/home?settings=integrations\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install lightning audiocraft torch numpy pandas torchaudio librosa matplotlib scipy\n",
    "!sudo apt install ffmpeg\n",
    "!git clone https://github.com/facebookresearch/audiocraft.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports and Dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling, audio processing, and deep learning.\n",
    "import os  # For interacting with the operating system (e.g., file paths).\n",
    "import numpy as np\n",
    "import pandas as pd  # For data manipulation and analysis.\n",
    "import torch  # PyTorch: A machine learning library for building models.\n",
    "import torch.nn as nn  # Neural network module in PyTorch.\n",
    "import torch.nn.functional as F  # Functional interface for PyTorch operations.\n",
    "import torchaudio  # PyTorch's audio processing library.\n",
    "import lightning.pytorch as L  # PyTorch Lightning: Simplifies PyTorch training.\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping  # Callbacks for saving models and stopping early.\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Learning rate scheduler to reduce learning rate on plateau.\n",
    "from audiocraft.models.musicgen import MusicGen  # Pretrained music generation model from Meta's AudioCraft.\n",
    "from audiocraft.modules.conditioners import ClassifierFreeGuidanceDropout  # For classifier-free guidance.\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset into training and validation sets.\n",
    "from audiocraft.data.audio import audio_write\n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Audio Dataset Class</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for loading audio and captions from a CSV file.\n",
    "class CSVAudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, audio_root, segment_duration=30, sample_rate=44100):\n",
    "        # Initialize the dataset with a DataFrame, root directory for audio files, segment duration, and sample rate.\n",
    "        self.df = df.reset_index(drop=True)  # Reset index of the DataFrame for consistent indexing.\n",
    "        self.audio_root = audio_root  # Root directory where audio files are stored.\n",
    "        self.segment_duration = segment_duration  # Duration of each audio segment in seconds.\n",
    "        self.sample_rate = sample_rate  # Sample rate for audio processing.\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset.\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get a single item from the dataset based on the given index.\n",
    "        row = self.df.iloc[idx]  # Retrieve the row corresponding to the index.\n",
    "        ytid = row['ytid']  # Extract the YouTube ID from the row.\n",
    "        audio_path = os.path.join(self.audio_root, f\"{ytid}.wav\")  # Construct the path to the audio file.\n",
    "        \n",
    "        waveform, sr = torchaudio.load(audio_path)  # Load the audio waveform and its sample rate.\n",
    "        if sr != self.sample_rate:\n",
    "            # Resample the audio if the sample rate does not match the desired rate.\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, self.sample_rate)\n",
    "        \n",
    "        if waveform.shape[0] > 1:\n",
    "            # If the audio has more than one channel, keep only the first channel.\n",
    "            waveform = waveform[0:1, :]\n",
    "        \n",
    "        num_samples = int(self.segment_duration * self.sample_rate)  # Calculate the number of samples for the segment.\n",
    "        if waveform.shape[1] > num_samples:\n",
    "            # If the waveform is longer than the segment duration, truncate it.\n",
    "            waveform = waveform[:, :num_samples]\n",
    "        else:\n",
    "            # If the waveform is shorter, pad it with zeros to match the segment duration.\n",
    "            waveform = F.pad(waveform, (0, num_samples - waveform.shape[1]))\n",
    "        \n",
    "        caption = row['caption']  # Extract the caption associated with the audio.\n",
    "        return waveform, caption  # Return the processed waveform and caption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Function for Condition Tensor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate condition tensors for classifier-free guidance.\n",
    "def get_condition_tensor(model, attributes):\n",
    "    null_conditions = ClassifierFreeGuidanceDropout(p=1.0)(attributes)  # Generate null conditions for classifier-free guidance.\n",
    "    conditions = attributes + null_conditions  # Combine original and null conditions.\n",
    "    tokenized = model.lm.condition_provider.tokenize(conditions)  # Tokenize the combined conditions.\n",
    "    cfg_conditions = model.lm.condition_provider(tokenized)  # Generate condition tensors from tokenized conditions.\n",
    "    return cfg_conditions  # Return the condition tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lightning Module for MusicGen Fine-Tuning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightningModule for fine-tuning the MusicGen model.\n",
    "class MusicGenFinetuning(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize the parent class.\n",
    "        self.model = MusicGen.get_pretrained(\"facebook/musicgen-Large\")  # Load the pretrained MusicGen model.\n",
    "        self.model.lm.train()  # Set the language model part of MusicGen to training mode.\n",
    "        self.model.lm = self.model.lm.float()  # Ensure the model uses float32 precision.\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Perform a single training step.\n",
    "        waveforms, captions = batch  # Unpack the batch into waveforms and captions.\n",
    "        waveforms = waveforms.to(self.device)  # Move waveforms to the appropriate device (GPU/CPU).\n",
    "        batch_size = waveforms.size(0)  # Get the batch size.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Encode the waveforms into discrete codes using the compression model.\n",
    "            codes, _ = self.model.compression_model.encode(waveforms)\n",
    "        \n",
    "        codes = codes.repeat_interleave(2, dim=0)  # Duplicate the codes for classifier-free guidance.\n",
    "        attributes, _ = self.model._prepare_tokens_and_attributes(captions, None)  # Prepare attributes from captions.\n",
    "        condition_tensors = get_condition_tensor(self.model, attributes)  # Generate condition tensors.\n",
    "        \n",
    "\n",
    "        lm_output = self.model.lm.compute_predictions(\n",
    "            codes=codes, \n",
    "            conditions=[], \n",
    "            condition_tensors=condition_tensors\n",
    "        )  # Compute predictions using the language model.\n",
    "        \n",
    "        logits = lm_output.logits  # Extract the logits from the model output.\n",
    "        mask = lm_output.mask  # Extract the mask indicating valid tokens.\n",
    "        logits_flat = logits[mask].view(-1, logits.size(-1))  # Flatten the logits for valid tokens.\n",
    "        targets_flat = codes[mask].view(-1)  # Flatten the target codes for valid tokens.\n",
    "        \n",
    "        loss = F.cross_entropy(logits_flat, targets_flat)  # Compute the cross-entropy loss.\n",
    "        accuracy = (logits_flat.argmax(-1) == targets_flat).float().mean()\n",
    "        \n",
    "        # Log training metrics.\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, batch_size=batch_size)\n",
    "        self.log(\"train_accuracy\", accuracy, prog_bar=True, batch_size=batch_size)\n",
    "        return loss  # Return the loss for optimization.\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Perform a single validation step.\n",
    "        waveforms, captions = batch  # Unpack the batch into waveforms and captions.\n",
    "        waveforms = waveforms.to(self.device)  # Move waveforms to the appropriate device.\n",
    "        batch_size = waveforms.size(0)  # Get the batch size.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Encode the waveforms into discrete codes using the compression model.\n",
    "            codes, _ = self.model.compression_model.encode(waveforms)\n",
    "        \n",
    "        codes = codes.repeat_interleave(2, dim=0)  # Duplicate the codes for classifier-free guidance.\n",
    "        attributes, _ = self.model._prepare_tokens_and_attributes(captions, None)  # Prepare attributes from captions.\n",
    "        condition_tensors = get_condition_tensor(self.model, attributes)  # Generate condition tensors.\n",
    "        \n",
    "        lm_output = self.model.lm.compute_predictions(\n",
    "            codes=codes, \n",
    "            conditions=[], \n",
    "            condition_tensors=condition_tensors\n",
    "        )  # Compute predictions using the language model.\n",
    "        \n",
    "        logits = lm_output.logits  # Extract the logits from the model output.\n",
    "        mask = lm_output.mask  # Extract the mask indicating valid tokens.\n",
    "        logits_flat = logits[mask].view(-1, logits.size(-1))  # Flatten the logits for valid tokens.\n",
    "        targets_flat = codes[mask].view(-1)  # Flatten the target codes for valid tokens.\n",
    "        \n",
    "        val_loss = F.cross_entropy(logits_flat, targets_flat)  # Compute the validation loss.\n",
    "        val_acc = (logits_flat.argmax(-1) == targets_flat).float().mean()  # Compute validation accuracy.\n",
    "       \n",
    "        # Log validation metrics.\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, batch_size=batch_size)\n",
    "        self.log(\"val_accuracy\", val_acc, prog_bar=True, batch_size=batch_size)\n",
    "        return val_loss  # Return the validation loss.\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Configure the optimizer and learning rate scheduler.\n",
    "        optimizer = torch.optim.AdamW(self.model.lm.parameters(), lr=1e-5)  # Use AdamW optimizer with a learning rate of 1e-5.\n",
    "        scheduler = ReduceLROnPlateau(  # Use a learning rate scheduler that reduces the learning rate on a plateau.\n",
    "            optimizer,\n",
    "            mode=\"min\",  # Monitor the metric to minimize (validation loss).\n",
    "            factor=0.1,  # Reduce the learning rate by a factor of 0.1.\n",
    "            patience=2,  # Wait for 2 epochs before reducing the learning rate.\n",
    "            verbose=True,  # Print messages when the learning rate is reduced.\n",
    "            min_lr=1e-6  # Set the minimum learning rate.\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,  # Return the optimizer.\n",
    "            \"lr_scheduler\": {  # Return the learning rate scheduler configuration.\n",
    "                \"scheduler\": scheduler,  # The scheduler object.\n",
    "                \"monitor\": \"val_loss\",  # Monitor the validation loss.\n",
    "                \"interval\": \"epoch\",  # Update the scheduler every epoch.\n",
    "                \"frequency\": 1,  # Frequency of updates.\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preparation and Dataloaders</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    L.seed_everything(42)  # Set a random seed for reproducibility.\n",
    "    \n",
    "    full_df = pd.read_csv(\"metadata_updated.csv\")  # Load the metadata CSV file.\n",
    "    train_df, val_df = train_test_split(full_df, test_size=0.2, random_state=42)  # Split the dataset into training and validation sets.\n",
    "    \n",
    "    train_dataset = CSVAudioDataset(  # Create the training dataset.\n",
    "        train_df, \n",
    "        audio_root=\"/teamspace/studios/this_studio/music_data\"\n",
    "    )\n",
    "    val_dataset = CSVAudioDataset(  # Create the validation dataset.\n",
    "        val_df, \n",
    "        audio_root=\"/teamspace/studios/this_studio/music_data\"\n",
    "    )\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(  # Create the training dataloader.\n",
    "        train_dataset,\n",
    "        batch_size=2,  # Batch size of 2.\n",
    "        shuffle=True,  # Shuffle the data for each epoch.\n",
    "        num_workers=2,  # Use 2 worker threads for data loading.\n",
    "        collate_fn=lambda x: (  # Custom collate function to handle batches.\n",
    "            torch.stack([sample[0] for sample in x]),\n",
    "            [sample[1] for sample in x]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(  # Create the validation dataloader.\n",
    "        val_dataset,\n",
    "        batch_size=2,  # Batch size of 2.\n",
    "        shuffle=False,  # Do not shuffle the validation data.\n",
    "        num_workers=2,  # Use 2 worker threads for data loading.\n",
    "        collate_fn=lambda x: (  # Custom collate function to handle batches.\n",
    "            torch.stack([sample[0] for sample in x]),\n",
    "            [sample[1] for sample in x]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training Configuration and Execution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params | Mode\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fd30498f674146b7d8068b7482cece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ed2c3c6519443ab6dd9d0b841a50b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfcf34ab52445eca6821957045afc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1026\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:151\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:370\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    368\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_model_zero_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:151\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:305\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_evaluation_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# enable train mode again\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:350\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_end\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 350\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:222\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 222\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:334\u001b[0m, in \u001b[0;36mModelCheckpoint.on_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_topk_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_last_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:385\u001b[0m, in \u001b[0;36mModelCheckpoint._save_topk_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    384\u001b[0m         warning_cache\u001b[38;5;241m.\u001b[39mwarn(m)\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_monitor_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:705\u001b[0m, in \u001b[0;36mModelCheckpoint._save_monitor_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_best_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:757\u001b[0m, in \u001b[0;36mModelCheckpoint._update_best_and_save\u001b[0;34m(self, current, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    753\u001b[0m     rank_zero_info(\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, global step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (best \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), saving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m     )\n\u001b[0;32m--> 757\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m del_filepath \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_remove_checkpoint(trainer, del_filepath, filepath):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:390\u001b[0m, in \u001b[0;36mModelCheckpoint._save_checkpoint\u001b[0;34m(self, trainer, filepath)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_save_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_global_step_saved \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mglobal_step\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1367\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m   1366\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mdump_checkpoint(weights_only)\n\u001b[0;32m-> 1367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.save_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:491\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[0;34m(self, checkpoint, filepath, storage_options)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/fabric/plugins/io/torch_io.py:58\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[0;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[1;32m     57\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_atomic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/fabric/utilities/cloud_io.py:85\u001b[0m, in \u001b[0;36m_atomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     84\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbytesbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# We use a transaction here to avoid file corruption if the save gets interrupted\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MusicGenFinetuning()  \u001b[38;5;66;03m# Instantiate the fine-tuning model.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(  \u001b[38;5;66;03m# Create the trainer.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m16-mixed\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Use mixed-precision training (FP16).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,  \u001b[38;5;66;03m# Train for a maximum of 10 epochs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Start the training process.\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = MusicGenFinetuning()  # Instantiate the fine-tuning model.\n",
    "trainer = L.Trainer(  # Create the trainer.\n",
    "    precision=\"16-mixed\",  # Use mixed-precision training (FP16).\n",
    "    max_epochs=10,  # Train for a maximum of 10 epochs.\n",
    "    val_check_interval=0.5,  # Check validation metrics every 50% of an epoch.\n",
    "    callbacks=[  # Add callbacks for checkpointing and early stopping.\n",
    "        ModelCheckpoint(monitor=\"val_loss\"),  # Save the best model based on validation loss.\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=3)  # Stop training if validation loss does not improve for 3 epochs.\n",
    "    ]\n",
    "    )\n",
    "trainer.fit(model, train_dataloader, val_dataloader)  # Start the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utility Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LMModel(\n",
       "  (cfg_dropout): ClassifierFreeGuidanceDropout(p=0.3)\n",
       "  (att_dropout): AttributeDropout({})\n",
       "  (condition_provider): ConditioningProvider(\n",
       "    (conditioners): ModuleDict(\n",
       "      (description): T5Conditioner(\n",
       "        (output_proj): Linear(in_features=768, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fuser): ConditionFuser()\n",
       "  (emb): ModuleList(\n",
       "    (0-3): 4 x ScaledEmbedding(2049, 1024)\n",
       "  )\n",
       "  (transformer): StreamingTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x StreamingTransformerLayer(\n",
       "        (self_attn): StreamingMultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (layer_scale_1): Identity()\n",
       "        (layer_scale_2): Identity()\n",
       "        (cross_attention): StreamingMultiheadAttention(\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (dropout_cross): Dropout(p=0.0, inplace=False)\n",
       "        (norm_cross): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_scale_cross): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (linears): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=1024, out_features=2048, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"lightning_logs/version_7/checkpoints/epoch=0-step=1490.ckpt\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "\n",
    "model = MusicGen.get_pretrained(\"facebook/musicgen-Large\")\n",
    "model.lm.load_state_dict(state_dict,strict=False)\n",
    "model.lm.float()\n",
    "model.lm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>UnConditional Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, num_samples, total_gen_len, temp=1.0, top_k=250):\n",
    "    model.set_generation_params(use_sampling=True, top_k=top_k, duration=30)\n",
    "\n",
    "    samples = []\n",
    "    prev_generated = None\n",
    "    descriptions = [None]\n",
    "\n",
    "    attributes, prompt_tokens = model._prepare_tokens_and_attributes(descriptions, None)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = model.lm.generate(\n",
    "            prev_generated,\n",
    "            attributes,\n",
    "            num_samples=1,\n",
    "            max_gen_len=total_gen_len,\n",
    "            remove_prompts=(i > 0),\n",
    "            temp=temp,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "\n",
    "        if sample.shape[2] == total_gen_len:\n",
    "            prev_generated = torch.clone(sample[..., total_gen_len // 2 :])\n",
    "        else:\n",
    "            prev_generated = torch.clone(sample)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_audio = model.compression_model.decode(sample, None) \n",
    "        del sample\n",
    "\n",
    "        gen_audio = gen_audio[0].detach().cpu().numpy().transpose(1, 0)\n",
    "        samples.append(gen_audio)\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def save_audio(samples, path):\n",
    "    audio = np.concatenate(samples, axis=0)\n",
    "    audio = np.squeeze(audio)\n",
    "    wavfile.write(path, 32000, audio.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(45)\n",
    "generated_audio = generate(model, num_samples=1, total_gen_len=1524)\n",
    "save_audio(generated_audio, \"generated_Audio2.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conditional Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: generated_music000.wav\n",
      "Waveform shape: (2, 960000)\n",
      "Waveform data (first 10 samples): [[ 0.18038043  0.17244084  0.1827398  ... -0.19096588 -0.1991812\n",
      "  -0.19858283]\n",
      " [ 0.03373905  0.02937443  0.08155953 ...  0.0873717   0.08849183\n",
      "   0.09535955]]\n"
     ]
    }
   ],
   "source": [
    "descriptions = [\"A dynamic blend of hip-hop and orchestral elements, with sweeping strings and brass, evoking the vibrant energy of the city.\"]\n",
    "model.set_generation_params(duration=30)\n",
    "generated_audio = model.generate(descriptions)\n",
    "from audiocraft.data.audio import audio_write\n",
    "\n",
    "for idx, audio_sample in enumerate(generated_audio):\n",
    "    filename = f\"generated_music{idx:03d}.wav\"  \n",
    "    waveform = audio_sample.cpu().numpy()  \n",
    "    \n",
    "    print(f\"Saving: {filename}\")  \n",
    "    print(f\"Waveform shape: {waveform.shape}\")  \n",
    "    print(f\"Waveform data (first 10 samples): {waveform[:10]}\")  \n",
    "\n",
    "    audio_write(filename, audio_sample.cpu(), model.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>plot the waveform</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# Load the generated WAV file\n",
    "waveform, sr = librosa.load(\"generated_music000.wav\", sr=None)\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.linspace(0, len(waveform)/sr, len(waveform)), waveform)\n",
    "plt.title(\"Waveform of Generated Music\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "print(\"Waveform:\", waveform[:960000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>done</h2>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
